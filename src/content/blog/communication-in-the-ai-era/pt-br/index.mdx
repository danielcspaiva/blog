---
title: Comunica√ß√£o na era da IA
description: Context Engineering √© apenas boa comunica√ß√£o.
date: 2025-08-19
tags: [blog, ai, communication, tech]
locale: pt-br
hideTableOfContents: true
---

---

## TL;DR

Comunica√ß√£o clara e contextual √© o catalisador tanto para humanos quanto para sistemas de IA. Inclua **objetivo**, **crit√©rios de sucesso**, **passos j√° tentados**, **ambiente/restri√ß√µes**, **artefatos/links** e um **pedido espec√≠fico**. **Por que isso importa:** reduz idas e voltas, diminui retrabalho e torna os resultados mais confi√°veis.

## Introdu√ß√£o

J√° escrevi antes que [o ingl√™s √© a habilidade mais importante que voc√™ precisa](/en/blog/english-is-the-ultimate-skill/). Ainda acredito que o ingl√™s seja inegoci√°vel, mas no fim das contas ele √© apenas uma ferramenta para algo mais amplo que eu subestimei na √©poca: **comunica√ß√£o**.

Se voc√™ trabalha com colegas de equipe ou com modelos de IA, isso se aplica a voc√™.

Hoje quero mostrar como a IA entra nessa equa√ß√£o, e por que a comunica√ß√£o eficaz se torna ainda mais cr√≠tica na era da IA.

## O problema humano-humano

Todos n√≥s j√° passamos por isso: voc√™ enfrenta um problema que n√£o consegue resolver e pede ajuda. Um amigo, colega, f√≥rum, chat ou outro sistema responde com perguntas como:

> Qual vers√£o voc√™ est√° usando?     
> Voc√™ leu a documenta√ß√£o?  
> Voc√™ tentou isso?     
> O que voc√™ j√° tentou?

Isso √© **contexto**, e na maioria das vezes √© imposs√≠vel ajudar sem ele.

No meu dia a dia, recebo mensagens como ‚ÄúAquela coisa n√£o funcionou‚Äù ou ‚ÄúHouve um problema‚Äù. Para realmente ajudar, preciso fazer algumas perguntas pra entender o real contexto, e muitas vezes isso leva um tempo.

Todas essas perguntas extras s√£o o pre√ßo que pagamos por **falta de contexto**.

Por que isso acontece:

- Nem sempre temos o entendimento completo da situa√ß√£o.  
- Subestimamos a import√¢ncia de expor os detalhes para quem est√° tentando nos ajudar.  
- √Äs vezes s√≥ temos pregui√ßa mesmo (eu incluso üòÖ).

## O problema humano-IA

Muita gente ainda trata LLMs como um Google em forma de chat. Eles n√£o s√£o: LLMs s√£o **assistentes probabil√≠sticos** que geram respostas a partir de padr√µes, n√£o um banco de dados onisciente e em tempo real.

Esses dias vi esse tweet do Thorsten Ball e achei que resumia bem:

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">What I find endlessly fascinating:<br /><br />Some engineers really can&#39;t seem to grasp that LLMs are non-deterministic and how to build software taking that into account.<br /><br />For others it immediately clicked, but for some it seems like there&#39;s a real mental barrier to accept it.</p>&mdash; Thorsten Ball (@thorstenball) <a href="https://twitter.com/thorstenball/status/1956017792484040731?ref_src=twsrc%5Etfw">August 14, 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Alguns conceitos que n√£o s√£o intuitivos mas s√£o muito importantes de entender:
- As respostas dos LLMs s√£o **n√£o determin√≠sticas**: ou seja, para a mesma pergunta, eles podem gerar respostas diferentes a cada vez, pois funcionam com base em probabilidades e n√£o em regras fixas.
- Modelos t√™m um **limite de conhecimento**: eles s√≥ sabem sobre fatos, eventos e tecnologias at√© a data em que foram treinados, e n√£o t√™m acesso a informa√ß√µes em tempo real ou acontecimentos recentes.  
- Eles podem **alucinar**: gerar respostas que n√£o correspondem √† realidade.

Tools e MCPs podem expandir suas capacidades, mas precisamos apontar o modelo para as ferramentas certas e explicar por que e como us√°-las.

Por isso, prompts vagos, no estilo de busca, podem ter um desempenho ruim. Trate o modelo como um colaborador: declare seu objetivo, crit√©rios de sucesso, contexto relevante (ambiente, restri√ß√µes), o que voc√™ j√° tentou e links para artefatos. Fa√ßa isso e a qualidade e confiabilidade sobem, e r√°pido.

Saber desses comportamentos b√°sicos das LLMs muda completamente a forma como voc√™ interage com elas: voc√™ passa a ser mais cuidadoso ao fornecer contexto, checar os outputs e estruturar melhor seus prompts. Isso faz toda a diferen√ßa na qualidade das respostas e na sua experi√™ncia com IA.

## Um exemplo pr√°tico: antes ‚Üí depois

**Antes (pouco contexto):**  
> ‚ÄúDeploy no Vercel falhou. Ajuda!‚Äù

**Depois (bom contexto, resumido):**  
> **Objetivo:** Fazer o build de produ√ß√£o passar novamente.  
> **Sintoma:** Deploys falham no Vercel desde o commit `b7c9d1e`, erro: `Module not found: '@/components/Button'`.  
> **Ambiente:** Next.js 14, Node 20, imagem de build do Vercel `2025.07`.  
> **O que j√° tentei:** Limpei `.next` + `.vercel`, reimplantei duas vezes, build local funciona.  
> **Links:** Log de build com falha [link], commit `b7c9d1e`.  
> **Pedido:** Identificar a causa (alias de path vs importa√ß√£o case-sensitive?) e sugerir corre√ß√£o ou rollback.  

Perceba como a vers√£o melhorada define um objetivo claro, nomeia o erro exato, mostra o que j√° foi tentado e traz evid√™ncias, tornando o problema solucion√°vel sem idas e voltas desnecess√°rias.

### Compara√ß√£o r√°pida

| Aspecto         | Prompt fraco                 | Prompt com contexto                                    |
|-----------------|------------------------------|--------------------------------------------------------|
| Clareza         | ‚ÄúDeploy falhou‚Äù              | Erro expl√≠cito + commit com falha                      |
| Evid√™ncia       | Nenhuma                      | Log do build + passos tentados                         |
| Resultado prov√°vel | Mais perguntas, perda de tempo | Diagn√≥stico direcionado, pr√≥ximo passo acion√°vel       |

## Context Engineering nada mais √© que uma boa comunica√ß√£o

Clareza e detalhe produzem resultados melhores. Quando voc√™ descreve exatamente o que est√° tentando fazer, o que aconteceu e o que j√° tentou, tanto humanos quanto IA conseguem ajudar muito mais do que se voc√™ apenas disser que algo deu errado.

Tobi L√ºtke, CEO do Shopify, resume bem:

<blockquote class="twitter-tweet" data-theme="light"><p lang="en" dir="ltr">I really like the term "context engineering" over prompt engineering. <br /><br />It describes the core skill better: the art of providing all the context for the task to be plausibly solvable by the LLM.</p>&mdash; tobi lutke (@tobi) <a href="https://twitter.com/tobi/status/1935533422589399127?ref_src=twsrc%5Etfw">19 de junho de 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Na pr√°tica, ‚ÄúContext Engineering‚Äù nada mais √© do que uma boa comunica√ß√£o aplicada √† IA: **d√™ ao modelo tudo o que um colega competente (ou voc√™ mesmo) precisaria para ter sucesso nessa tarefa.**

## Conclus√£o

Na era da IA, comunicar contexto com clareza deixou de ser opcional, √© a base para resultados consistentes. Como bem disse Guillermo Rauch, CEO da Vercel, o sucesso passa a depender diretamente da qualidade dos seus pensamentos:

<blockquote class="twitter-tweet" data-theme="light"><p lang="en" dir="ltr">Imagine success being determined purely based on the quality of your thoughts. That's the promise of AI</p>&mdash; Guillermo Rauch (@rauchg) <a href="https://twitter.com/rauchg/status/1956356467898114443?ref_src=twsrc%5Etfw">15 de agosto de 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

No fim do dia, comunicar bem √© pensar bem, e pensar bem √© a maior vantagem competitiva que voc√™ pode ter. **Contexto claro multiplica resultados.**