---
title: ComunicaÃ§Ã£o na era da IA
description: Context Engineering Ã© apenas boa comunicaÃ§Ã£o.
date: 2025-08-19
tags: [blog, ai, communication, tech]
locale: pt-br
hideTableOfContents: true
---

---

## Resumo

ComunicaÃ§Ã£o clara e contextual Ã© o catalisador tanto para humanos quanto para sistemas de IA. Inclua **objetivo**, **critÃ©rios de sucesso**, **passos jÃ¡ tentados**, **ambiente/restriÃ§Ãµes**, **artefatos/links** e um **pedido especÃ­fico**. **Por que isso importa:** reduz idas e voltas, diminui retrabalho e torna os resultados mais confiÃ¡veis.

## IntroduÃ§Ã£o

JÃ¡ [argumentei antes que o inglÃªs Ã© a habilidade definitiva](/en/blog/english-is-the-ultimate-skill/). Ainda acredito que o inglÃªs Ã© incrivelmente importante, mas no fim das contas ele Ã© apenas uma ferramenta para algo mais amplo que eu subestimei na Ã©poca: **comunicaÃ§Ã£o**.

Se vocÃª trabalha com colegas de equipe ou com modelos de IA, isso se aplica a vocÃª.

Hoje quero mostrar como a IA entra nessa equaÃ§Ã£o, e por que a comunicaÃ§Ã£o eficaz se torna ainda mais crÃ­tica na era da IA.

## O problema humano-humano

Todos nÃ³s jÃ¡ passamos por isso: vocÃª enfrenta um problema que nÃ£o consegue resolver e pede ajuda. Um amigo, colega, fÃ³rum, chat ou outro sistema responde com perguntas de de follow up como: â€œQual versÃ£o vocÃª estÃ¡ usando?â€, â€œVocÃª leu a documentaÃ§Ã£o?â€, â€œVocÃª tentou isso?â€.

Isso Ã© **contexto**, e na maioria das vezes Ã© impossÃ­vel ajudar sem ele.

No meu dia a dia, recebo mensagens como â€œAquela coisa nÃ£o funcionouâ€ ou â€œHouve um problemaâ€. Para realmente ajudar, preciso fazer algumas perguntas pra entender o real contexto, e muitas vezes isso leva um tempo.

Todas essas perguntas extras sÃ£o o imposto que pagamos por **falta de contexto**.

Por que isso acontece:

- Nem sempre temos o entendimento completo da situaÃ§Ã£o.  
- Subestimamos a importÃ¢ncia de expor os detalhes para quem estÃ¡ tentando nos ajudar.  
- Ã€s vezes Ã© sÃ³ preguiÃ§a mesmo (eu incluso ğŸ˜…).

## O problema humano-IA

Muita gente ainda trata LLMs como um Google em forma de chat. Eles nÃ£o sÃ£o: LLMs sÃ£o **assistentes probabilÃ­sticos** que geram respostas a partir de padrÃµes, nÃ£o um banco de dados onisciente e em tempo real.

Esses dias vi esse tweet do Thorsten Ball e achei que resumia bem:

<blockquote class="twitter-tweet" data-theme="light"><p lang="en" dir="ltr">One thing that feels wrong to me about the current LLM hype is that a lot of people seem to think that LLMs work like search engines, but with a chat interface.</p>&mdash; Thorsten Ball (@thorstenball) <a href="https://twitter.com/thorstenball/status/1956017792484040731?ref_src=twsrc%5Etfw">15 de agosto de 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Na prÃ¡tica:
- As respostas dos LLMs sÃ£o **nÃ£o determinÃ­sticas**: ou seja, para a mesma pergunta, eles podem gerar respostas diferentes a cada vez, pois funcionam com base em probabilidades e nÃ£o em regras fixas.
- Modelos tÃªm um **limite de conhecimento**: eles sÃ³ sabem sobre fatos, eventos e tecnologias atÃ© a data em que foram treinados, e nÃ£o tÃªm acesso a informaÃ§Ãµes em tempo real ou acontecimentos recentes.  
- Eles podem **alucinar**: gerar respostas que nÃ£o correspondem Ã  realidade.

Tools e MCPs podem expandir suas capacidades, mas precisamos apontar o modelo para as ferramentas certas e explicar por que.

Por isso, prompts vagos, no estilo de busca, tÃªm desempenho ruim. Trate o modelo como um colaborador: declare seu objetivo, critÃ©rios de sucesso, contexto relevante (ambiente, restriÃ§Ãµes), o que vocÃª jÃ¡ tentou e links para artefatos. FaÃ§a isso e a qualidade e confiabilidade sobem, e rÃ¡pido.

Saber desses comportamentos bÃ¡sicos das LLMs muda completamente a forma como vocÃª interage com elas: vocÃª passa a ser mais cuidadoso ao fornecer contexto, checar os outputs e estruturar melhor seus prompts. Isso faz toda a diferenÃ§a na qualidade das respostas e na sua experiÃªncia com IA.

## Um exemplo prÃ¡tico: antes â†’ depois

**Antes (pouco contexto):**  
> â€œDeploy no Vercel falhou. Ajuda!â€

**Depois (bom contexto, resumido):**  
> **Objetivo:** Fazer o build de produÃ§Ã£o passar novamente.  
> **Sintoma:** Deploys falham no Vercel desde o commit `b7c9d1e`, erro: `Module not found: '@/components/Button'`.  
> **Ambiente:** Next.js 14, Node 20, imagem de build do Vercel `2025.07`.  
> **O que jÃ¡ tentei:** Limpei `.next` + `.vercel`, reimplantei duas vezes, build local funciona.  
> **Links:** Log de build com falha [link], commit `b7c9d1e`.  
> **Pedido:** Identificar a causa (alias de path vs importaÃ§Ã£o case-sensitive?) e sugerir correÃ§Ã£o ou rollback.  

Perceba como a versÃ£o melhorada define um objetivo claro, nomeia o erro exato, mostra o que jÃ¡ foi tentado e traz evidÃªncias â€” tornando o problema solucionÃ¡vel sem idas e voltas desnecessÃ¡rias.

### ComparaÃ§Ã£o rÃ¡pida

| Aspecto         | Prompt fraco                 | Prompt com contexto                                    |
|-----------------|------------------------------|--------------------------------------------------------|
| Clareza         | â€œDeploy falhouâ€              | Erro explÃ­cito + commit com falha                      |
| EvidÃªncia       | Nenhuma                      | Log do build + passos tentados                         |
| Resultado provÃ¡vel | Mais perguntas, perda de tempo | DiagnÃ³stico direcionado, prÃ³ximo passo acionÃ¡vel       |

## Context Engineering Ã© apenas boa comunicaÃ§Ã£o

Clareza e detalhe produzem resultados melhores. Quando vocÃª descreve exatamente o que estÃ¡ tentando fazer, o que aconteceu e o que jÃ¡ tentou, tanto humanos quanto IA conseguem ajudar muito mais do que se vocÃª apenas disser que algo deu errado.

Tobi LÃ¼tke resume bem:

<blockquote class="twitter-tweet" data-theme="light"><p lang="en" dir="ltr">I really like the term "context engineering" over prompt engineering. <br /><br />It describes the core skill better: the art of providing all the context for the task to be plausibly solvable by the LLM.</p>&mdash; tobi lutke (@tobi) <a href="https://twitter.com/tobi/status/1935533422589399127?ref_src=twsrc%5Etfw">19 de junho de 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Na prÃ¡tica, â€œContext Engineeringâ€ nada mais Ã© do que comunicaÃ§Ã£o excelente aplicada Ã  IA: **dÃª ao modelo tudo o que um colega competente (ou vocÃª mesmo) precisaria para ter sucesso.**

## ConclusÃ£o

A comunicaÃ§Ã£o sempre foi o motor da colaboraÃ§Ã£o e da soluÃ§Ã£o de problemas. Na era da IA, isso importa ainda mais: nossa capacidade de transmitir contexto com clareza muitas vezes determina quÃ£o bem conseguimos usar essas ferramentas.

Como Guillermo Rauch colocou, a IA faz o sucesso depender diretamente da qualidade dos seus pensamentos. Por isso, boa comunicaÃ§Ã£o deixou de ser opcional, e se tornou a chave:

<blockquote class="twitter-tweet" data-theme="light"><p lang="en" dir="ltr">Imagine success being determined purely based on the quality of your thoughts. That's the promise of AI</p>&mdash; Guillermo Rauch (@rauchg) <a href="https://twitter.com/rauchg/status/1956356467898114443?ref_src=twsrc%5Etfw">15 de agosto de 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Invista em comunicaÃ§Ã£o, seja com humanos ou com IA, e vocÃª colherÃ¡ retornos cada vez maiores Ã  medida que essas tecnologias se tornem ainda mais presentes no nosso trabalho diÃ¡rio.